

@incollection{Thrun95,
  title={Lifelong robot learning},
  author={Thrun, Sebastian and Mitchell, Tom M},
  booktitle={The biology and technology of intelligent autonomous agents},
  pages={165--196},
  year={1995},
  publisher={Springer},
  keywords={Classics},
  url={http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.71.3723&rep=rep1&type=pdf}
}
@String(Thrun95="Argues knowledge transfer is essential if robots are to learn control with moderate learning times")

@article{Farquhar18,
  title={Towards Robust Evaluations of Continual Learning},
  author={Farquhar, Sebastian and Gal, Yarin},
  journal={arXiv preprint arXiv:1805.09733},
  year={2018},
  keywords={Influentials, },
  url={https://arxiv.org/abs/1805.09733},
}
@String(Farquhar18="Proposes desideratas and reexamines the evaluation protocol")

@inproceedings{Chaudhry19,
  title={Efficient Lifelong Learning with A-GEM},
  author={Chaudhry, Arslan and Ranzato, Marc’Aurelio and Rohrbach, Marcus and Elhoseiny, Mohamed},
  booktitle={ICLR},
  year={2019},
  url={https://arxiv.org/abs/1812.00420},
    keywords={Rehearsal, Influential}
}
@String(Chaudhry19="More efficient GEM; Introduces online continual learning")

@article{Kirkpatrick17,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proc. of the national academy of sciences},
  year={2017},
  publisher={National Acad Sciences},
    keywords={Regularization, Influential},
    url={https://www.pnas.org/content/pnas/114/13/3521.full.pdf},
}
@String(Kirkpatrick17="Introduces prior-focused methods (Elastic Weight Consolidation)")


@incollection{Lopez-Paz17,
title={Gradient Episodic Memory for Continual Learning},
author={Lopez-Paz, David and Ranzato, Marc-Aurelio},
booktitle={Advances in Neural Information Processing Systems 30},
editor={I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages={6467--6476},
year={2017},
publisher={Curran Associates, Inc.},
url={http://papers.nips.cc/paper/7225-gradient-episodic-memory-for-continual-learning.pdf},
    keywords={Rehearsal, Influential}
}
@String(Lopez-Paz17="A model that alliviates CF via constrained optimization")


@inproceedings{Shin17,
  title={Continual learning with deep generative replay},
  author={Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2990--2999},
  year={2017},
    keywords={Generative Replay, Influential},
    url={https://arxiv.org/abs/1705.08690},
}
@String(Shin17="Introduces generative replay")

@ARTICLE{Goodfellow13,
   author={Goodfellow, I.~J. and Mirza, M. and Xiao, D. and Courville, A. and Bengio, Y.},
    title="An Empirical Investigation of Catastrophic Forgetting in Gradient-Based Neural Networks",
  journal={ArXiv e-prints},
archivePrefix="arXiv",
   eprint={1312.6211},
 primaryClass="stat.ML",
 keywords={Statistics - Machine Learning, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing, Empirical Study, Influential},
     year={2013},
    month={dec},
   adsurl={http://adsabs.harvard.edu/abs/2013arXiv1312.6211G},
  adsnote={Provided by the SAO/NASA Astrophysics Data System},
  url={https://arxiv.org/abs/1705.08690},
}
@String(Goodfellow13="Investigates CF in neural networks")

@misc{lange2019continual,
    title={Continual learning: A comparative study on how to defy forgetting in classification tasks},
    author={Matthias De Lange and Rahaf Aljundi and Marc Masana and Sarah Parisot and Xu Jia and Ales Leonardis and Gregory Slabaugh and Tinne Tuytelaars},
    year={2019},
    eprint={1909.08383},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    keywords="Survey",
    url={https://arxiv.org/abs/1909.08383},
}
@String(lange2019continual="Extensive empirical study of CL methods (in the multi-head setting)")

@article{Parisi18review,
title="Continual lifelong learning with neural networks: A review",
journal="Neural Networks",
volume="113",
pages="54 - 71",
year="2019",
issn="0893-6080",
doi="https://doi.org/10.1016/j.neunet.2019.01.012",
url="http://www.sciencedirect.com/science/article/pii/S0893608019300231",
author="German I. Parisi and Ronald Kemker and Jose L. Part and Christopher Kanan and Stefan Wermter",
keywords="Continual learning, Lifelong learning, Catastrophic forgetting, Developmental systems, Memory consolidation, Survey"
}
@String(Parisi18review="An extensive review of CL")

@inproceedings{hung2019compacting,
  title={Compacting, Picking and Growing for Unforgetting Continual Learning},
  author={Hung, Ching-Yi and Tu, Cheng-Hao and Wu, Cheng-En and Chen, Chien-Hung and Chan, Yi-Ming and Chen, Chu-Song},
  booktitle={Advances in Neural Information Processing Systems},
  pages={13647--13657},
  year={2019},
    keywords={Hybrid},
    url={https://arxiv.org/abs/1910.06562}
}
@String(hung2019compacting="Approach leverages the principles of deep model compression, critical weights selection, and progressive networks expansion. All enforced in an iterative manner")

@article{Swaroop2019ImprovingAU,
  title={Improving and Understanding Variational Continual Learning},
  author={Siddharth Swaroop and Cuong V. Nguyen and Thang D. Bui and Richard E. Turner},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.02099},
    keywords={Regularization},
    url="https://arxiv.org/abs/1905.02099"
})
@String(Swaroop2019ImprovingAU="Improved results and interpretation of VCL.")


@inproceedings{Ebrahimi2020Uncertainty-guided,
title={Uncertainty-guided Continual Learning with Bayesian Neural Networks},
author={Sayna Ebrahimi and Mohamed Elhoseiny and Trevor Darrell and Marcus Rohrbach},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HklUCCVKDB}
}
@String(Ebrahimi2020Uncertainty-guided="Uses Bayes by Backprop for variational Continual Learning.")

@incollection{NIPS2019_8690,
title={Uncertainty-based Continual Learning with Adaptive Regularization},
author={Ahn, Hongjoon and Cha, Sungmin and Lee, Donggyu and Moon, Taesup},
booktitle={Advances in Neural Information Processing Systems 32},
editor={H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages={4394--4404},
year={2019},
publisher={Curran Associates, Inc.},
url={http://papers.nips.cc/paper/8690-uncertainty-based-continual-learning-with-adaptive-regularization.pdf},
    keywords={Regularization}
}
@String(NIPS2019_8690="Introduces VCL with uncertainty measured for neurons instead of weights.")

@misc{zeno2018task,
    title={Task Agnostic Continual Learning Using Online Variational Bayes},
    author={Chen Zeno and Itay Golan and Elad Hoffer and Daniel Soudry},
    year={2018},
    eprint={1803.10123},
    archivePrefix={arXiv},
    primaryClass={stat.ML},
    keywords={Regularization},
    url={https://arxiv.org/pdf/1803.10123.pdf}
}
@String(zeno2018task="Introduces an optimizer for CL that relies on closed form updates of mu and sigma of BNN; introduce label trick for class learning (single-head)")

@article{DBLP:journals/corr/abs-1902-09432,
  author   ={Jaehong Yoon and
               Saehoon Kim and
               Eunho Yang and
               Sung Ju Hwang},
  title    ={ORACLE: Order Robust Adaptive Continual Learning},
  journal  ={CoRR},
  volume   ={abs/1902.09432},
  year     ={2019},
  url      ={http://arxiv.org/abs/1902.09432},
  archivePrefix={arXiv},
  eprint   ={1902.09432},
  timestamp={Tue, 21 May 2019 18:03:36 +0200},
  biburl   ={https://dblp.org/rec/journals/corr/abs-1902-09432.bib},
  bibsource={dblp computer science bibliography, https://dblp.org},
    keywords={Dynamic Architecture}
}




@article{Rajasegaran2019Random,
  author   ={Jathushan Rajasegaran and
               Munawar Hayat and
               Salman H. Khan and
               Fahad Shahbaz Khan and
               Ling Shao},
  title    ={Random Path Selection for Incremental Learning},
  journal  ={CoRR},
  volume   ={abs/1906.01120},
  year     ={2019},
  url      ={http://arxiv.org/abs/1906.01120},
  archivePrefix={arXiv},
  eprint   ={1906.01120},
  timestamp={Fri, 06 Dec 2019 16:34:40 +0100},
  biburl   ={https://dblp.org/rec/journals/corr/abs-1906-01120.bib},
  bibsource={dblp computer science bibliography, https://dblp.org},
    keywords={Dynamic Architecture}
}
@String(Rajasegaran2019Random="Proposes a random path selection algorithm, called RPSnet, that progressively chooses optimal paths for the new tasks while encouraging parameter sharing and reuse")




@inproceedings{He18,
title={Overcoming Catastrophic Interference using Conceptor-Aided Backpropagation},
author={Xu He and Herbert Jaeger},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=B1al7jg0b},
    keywords={Regularization}
}
@String(He18="Conceptor-Aided Backprop (CAB): gradients are shielded by conceptors against degradation of previously learned tasks")

@inproceedings{Pentina15,
  title={Lifelong learning with non-iid tasks},
  author={Pentina, Anastasia and Lampert, Christoph H},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1540--1548},
  year={2015},
    keywords={}
}


@article{Serra18,
  title=	 {Overcoming Catastrophic Forgetting with Hard Attention to the Task},
  author=	 {Serra, Joan and Suris, Didac and Miron, Marius and Karatzoglou, Alexandros},
  journal  ={ICML},
  booktitle=	 {Proceedings of the 35th International Conference on Machine Learning},
  pages=	 {4548--4557},
  year=	 {2018},
  editor=	 {Dy, Jennifer and Krause, Andreas},
  volume=	 {80},
  series=	 {Proceedings of Machine Learning Research},
  address=	 {Stockholmsmässan, Stockholm Sweden},
  month=	 {10--15 Jul},
  publisher=	 {PMLR},
  pdf=	 {http://proceedings.mlr.press/v80/serra18a/serra18a.pdf},
  url=	 {http://proceedings.mlr.press/v80/serra18a.html},
    keywords={Regularization}
}
@String(Serra18="Introducing a hard attention idea with binary masks")

@inproceedings{chaudhry2018riemannian,
  title={Riemannian Walk for Incremental Learning: Understanding Forgetting and Intransigence},
  author={Chaudhry, Arslan and Dokania, Puneet K and Ajanthan, Thalaiyasingam and Torr, Philip HS},
  booktitle={ECCV},
  year={2018},
    keywords={Regularization},
    url={https://arxiv.org/abs/1801.10112}
}
@String(chaudhry2018riemannian="Formalizes the shortcomings of multi-head evaluation, as well as the importance of replay in single-head setup. Presenting an improved version of EWC.")




@article{Aljundi17,
  author   ={Rahaf Aljundi and Francesca Babiloni and Mohamed Elhoseiny and Marcus Rohrbach and Tinne Tuytelaars},
  title    ={Memory Aware Synapses: Learning what (not) to forget},
  journal  ={CoRR},
  volume   ={abs/1711.09601},
  year     ={2017},
  url      ={http://arxiv.org/abs/1711.09601},
  archivePrefix={arXiv},
  eprint   ={1711.09601},
  timestamp={Mon, 13 Aug 2018 16:47:14 +0200},
  biburl   ={https://dblp.org/rec/bib/journals/corr/abs-1711-09601},
  bibsource={dblp computer science bibliography, https://dblp.org},
    keywords={Regularization}
}
@String(Aljundi17="Importance of parameter measured based on their contribution to change in the learned prediction function")



@inproceedings{Nguyen17,
    title={Variational Continual Learning},
    author={Cuong V. Nguyen and Yingzhen Li and Thang D. Bui and Richard E. Turner},
    booktitle={International Conference on Learning Representations},
    year={2018},
    keywords={Regularization},
    url={https://arxiv.org/abs/1710.10628}
}
@String(Nguyen17="Introduces the idea of using previous task's posterior as the new task's prior in a BNN.")


@inproceedings{schwarz2018progress,
  title={Progress \& compress: A scalable framework for continual learning},
  author={Schwarz, Jonathan and Luketina, Jelena and Czarnecki, Wojciech M and Grabska-Barwinska, Agnieszka and Teh, Yee Whye and Pascanu, Razvan and Hadsell, Raia},
  booktitle={ICML},
  year={2018},
    keywords={Regularization},
    url={https://arxiv.org/abs/1805.06370}
}
@String(schwarz2018progress="A new P\&C architecture; online EWC for keeping the knowledge about the previous task, knowledge for keeping the knowledge about the current task (Multi-head setting, RL)")

@InProceedings{Zenke17,
  title=	 {Continual Learning Through Synaptic Intelligence},
  author=	 {Zenke, Friedeman and Poole, Ben and Ganguli, Surya },
  booktitle=	 {Proceedings of the 34th International Conference on Machine Learning},
  pages=	 {3987--3995},
  year=	 {2017},
  editor=	 {Doina Precup and Yee Whye Teh},
  volume=	 {70},
  series=	 {Proceedings of Machine Learning Research},
  address=	 {International Convention Centre, Sydney, Australia},
  month=	 {06--11 Aug},
  publisher=	 {PMLR},
  pdf=	 {http://proceedings.mlr.press/v70/zenke17a/zenke17a.pdf},
  url=	 {http://proceedings.mlr.press/v70/zenke17a.html},
    keywords={Regularization}
}
@String(Zenke17="Synaptic Intelligence (SI). Importance of parameter measured based on their contribution to change in the loss. ")

@article{Li17,
  title={Learning without forgetting},
  author={Li, Zhizhong and Hoiem, Derek},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2017},
  publisher={IEEE},
    keywords={Distillation},
    url={https://arxiv.org/abs/1606.09282}
}
@String(Li17="Functional regularization through distillation (keeping the output of the updated network on the new data close to the output of the old network on the new data)")


@misc{li2019continual,
    title={Continual Learning Using Bayesian Neural Networks},
    author={HongLin Li and Payam Barnaghi and Shirin Enshaeifar and Frieder Ganz},
    year={2019},
    eprint={1910.04112},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    keywords={}
}

@misc{
rosenfeld2018incremental,
title={Incremental Learning through Deep Adaptation},
author={Amir Rosenfeld and John K. Tsotsos},
year={2018},
url={https://openreview.net/forum?id=ryj0790hb},
    keywords={Dynamic Architecture}
}

@ARTICLE{Rusu16progressive,
   author={{Rusu}, A.~A. and {Rabinowitz}, N.~C. and {Desjardins}, G. and 
	{Soyer}, H. and {Kirkpatrick}, J. and {Kavukcuoglu}, K. and 
	{Pascanu}, R. and {Hadsell}, R.},
    title={Progressive Neural Networks},
  journal={ArXiv e-prints},
archivePrefix="arXiv",
   eprint={1606.04671},
 primaryClass="cs.LG",
 keywords={Computer Science - Learning, Dynamic Architecture},
     year=2016,
    month={jun},
   adsurl={http://adsabs.harvard.edu/abs/2016arXiv160604671R},
  adsnote={Provided by the SAO/NASA Astrophysics Data System},
   url={https://arxiv.org/abs/1606.04671}
}
@String(Rusu16progressive="Each task have a specific model connected to the previous ones")

@misc{farajtabar2019orthogonal,
    title={Orthogonal Gradient Descent for Continual Learning},
    author={Mehrdad Farajtabar and Navid Azizan and Alex Mott and Ang Li},
    year={2019},
    eprint={1910.07104},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    keywords={Rehearsal},
url={https://arxiv.org/abs/1910.07104},
}
@String(farajtabar2019orthogonal="projecting the gradients from new tasks onto a subspace in which the neural network output on previous task does not change and the projected gradient is still in a useful direction for learning the new task")


@incollection{Aljundi2019Gradient,
title={Gradient based sample selection for online continual learning},
author={Aljundi, Rahaf and Lin, Min and Goujaud, Baptiste and Bengio, Yoshua},
booktitle={Advances in Neural Information Processing Systems 32},
editor={H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages={11816--11825},
year={2019},
publisher={Curran Associates, Inc.},
url={http://papers.nips.cc/paper/9354-gradient-based-sample-selection-for-online-continual-learning.pdf},
    keywords={Rehearsal}
}
@String(Aljundi2019Gradient="sample selection as a constraint reduction problem based on the constrained optimization view of continual learning")


@incollection{Aljundi2019Online,
title ={Online Continual Learning with Maximal Interfered Retrieval},
author={Aljundi, Rahaf and Caccia, Lucas and Belilovsky, Eugene and Caccia, Massimo and Lin, Min and Charlin, Laurent and Tuytelaars, Tinne},
booktitle={Advances in Neural Information Processing Systems 32},
editor={H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages={11849--11860},
year={2019},
publisher={Curran Associates, Inc.},
url={http://papers.nips.cc/paper/9357-online-continual-learning-with-maximal-interfered-retrieval.pdf},
keywords={Rehearsal}
}
@String(Aljundi2019Online="Controlled sampling of memories for replay to automatically rehearse on tasks currently undergoing the most forgetting")


@article{caccia2019online,
  title={Online Learned Continual Compression with Adaptative Quantization Module},
  author={Caccia, Lucas and Belilovsky, Eugene and Caccia, Massimo and Pineau, Joelle},
  journal={arXiv preprint arXiv:1911.08019},
  year={2019},
    keywords={Rehearsal},
    url={https://arxiv.org/abs/1911.08019}
}
@String(caccia2019online="Uses stacks of VQ-VAE modules to progressively compress the data stream, enabling better rehearsal")


@article{Ven2018GenerativeRW,
  title={Generative replay with feedback connections as a general strategy for continual learning},
  author={Michiel van der Ven and Andreas S. Tolias},
  journal={ArXiv},
  year={2018},
  volume={abs/1809.10635},
    keywords={Generative Replay},
    url={https://arxiv.org/abs/1809.10635}
}
@String(Ven2018GenerativeRW="smarter Generative Replay")

@incollection{Javed2019Meta,
title={Meta-Learning Representations for Continual Learning},
author={Javed, Khurram and White, Martha},
booktitle={Advances in Neural Information Processing Systems 32},
editor={H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages={1818--1828},
year={2019},
publisher={Curran Associates, Inc.},
url={http://papers.nips.cc/paper/8458-meta-learning-representations-for-continual-learning.pdf},
    keywords={Meta-Continual Learning}
}
@String(Javed2019Meta="Introduces Learns how to continually learn (OML) i.e. learns how to do online updates without forgetting.")

@misc{luo2019learning,
    title={Learning from the Past: Continual Meta-Learning via Bayesian Graph Modeling},
    author={Yadan Luo and Zi Huang and Zheng Zhang and Ziwei Wang and Mahsa Baktashmotlagh and Yang Yang},
    year={2019},
    eprint={1911.04695},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    keywords={Continual-Meta Learning},
    url={https://arxiv.org/abs/1911.04695}
}

@inproceedings{
Kurle2020Continual,
title={Continual Learning with Bayesian Neural Networks for Non-Stationary Data},
author={Richard Kurle and Botond Cseke and Alexej Klushyn and Patrick van der Smagt and Stephan Günnemann},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SJlsFpVtDB},
    keywords={Regularization}
}
@String(Kurle2020Continual="continual learning for non-stationary data using Bayesian neural networks and memory-based online variational Bayes")

@InProceedings{pmlr-v97-finn19a,
  title=	 {Online Meta-Learning},
  author=	 {Finn, Chelsea and Rajeswaran, Aravind and Kakade, Sham and Levine, Sergey},
  booktitle=	 {Proceedings of the 36th International Conference on Machine Learning},
  pages=	 {1920--1930},
  year=	 {2019},
  editor=	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume=	 {97},
  series=	 {Proceedings of Machine Learning Research},
  address=	 {Long Beach, California, USA},
  month=	 {09--15 Jun},
  publisher=	 {PMLR},
  pdf=	 {http://proceedings.mlr.press/v97/finn19a/finn19a.pdf},
  url=	 {http://proceedings.mlr.press/v97/finn19a.html},
    keywords={Continual-Meta Learning}
}
@String(pmlr-v97-finn19a="defines Online Meta-learning; propsoses Follow the Meta Leader (FTML) (~ Online MAML)")


@incollection{NIPS2019_9112,
title={Reconciling meta-learning and continual learning with online mixtures of tasks},
author={Jerfel, Ghassen and Grant, Erin and Griffiths, Tom and Heller, Katherine A},
booktitle={Advances in Neural Information Processing Systems 32},
editor={H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages={9119--9130},
year={2019},
publisher={Curran Associates, Inc.},
url={http://papers.nips.cc/paper/9112-reconciling-meta-learning-and-continual-learning-with-online-mixtures-of-tasks.pdf},
    keywords={Continual-Meta Learning}
}
@String(NIPS2019_9112="Meta-learns a tasks structure; continual adaptation via non-parametric prior")


@inproceedings{
nagabandi2018deep,
title={Deep Online Learning Via Meta-Learning: Continual Adaptation for Model-Based RL},
author={Anusha Nagabandi and Chelsea Finn and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HyxAfnA5tm},
    keywords={Continual-Meta Learning}
}
@String(nagabandi2018deep="Formulates an online learning procedure that uses SGD to update model parameters, and an EM with a Chinese restaurant process prior to develop and maintain a mixture of models to handle non-stationary task distribution")

@misc{rao2019continual,
    title={Continual Unsupervised Representation Learning},
    author={Dushyant Rao and Francesco Visin and Andrei A. Rusu and Yee Whye Teh and Razvan Pascanu and Raia Hadsell},
    year={2019},
    eprint={1910.14481},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    keywords={Generative Modeling},
    url={https://arxiv.org/pdf/1910.14481.pdf}
}
@String(rao2019continual="Introduces unsupervised continual learning (no task label and no task boundaries)")

@inproceedings{lesort2018generative,
  TITLE={Generative Models from the perspective of Continual Learning},
  AUTHOR={Lesort, Timoth{\'e}e and Caselles-Dupr{\'e}, Hugo and Garcia-Ortiz, Michael and Goudou, Jean-Fran{\c c}ois and Filliat, David},
  URL={https://hal.archives-ouvertes.fr/hal-01951954},
  BOOKTITLE={{IJCNN - International Joint Conference on Neural Networks}},
  ADDRESS={Budapest, Hungary},
  YEAR={2019},
  MONTH={Jul},
  PDF={https://hal.archives-ouvertes.fr/hal-01951954/file/_NIPS_CL_Workshop__Continual_learning_for_generative_models.pdf},
  HAL_ID={hal-01951954},
  keywords={"Generative Modeling", "Generative Replay"},
  HAL_VERSION={v1},
}
@String(lesort2018generative="Extensive evaluation of CL methods for generative modeling")

@article{Ramapuram17,
  title={Lifelong Generative Modeling},
  author={Ramapuram, Jason and Gregorova, Magda and Kalousis, Alexandros},
  journal={arXiv preprint arXiv:1705.09847},
  year={2017},
    keywords={Generative Modeling},
  url={https://arxiv.org/abs/1705.09847}
}
@String(Ramapuram17="first to focus on continual generative modeling (DGR's focus was still on continual supervised learning)")

@inproceedings{Alet2018ModularM,
  title={Modular meta-learning},
  author={Ferran Alet and Tom{\'a}s Lozano-P{\'e}rez and Leslie Pack Kaelbling},
  booktitle={CoRL},
  year={2018},
    keywords={}
}

@inproceedings{
toneva2018an,
title={An Empirical Study of Example Forgetting during Deep Neural Network Learning},
author={Mariya Toneva and Alessandro Sordoni and Remi Tachet des Combes and Adam Trischler and Yoshua Bengio and Geoffrey J. Gordon},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=BJlxm30cKm},
    keywords={}
}

@inproceedings{
Oswald2020Continual,
title={Continual learning with hypernetworks},
author={Johannes von Oswald and Christian Henning and João Sacramento and Benjamin F. Grewe},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SJgwNerKvB},
    keywords={Hybrid}
}
@String(Oswald2020Continual="Learning task-conditioned hypernetworks for continual learning as well as task embeddings; hypernetwors offers good model compression.")

@inproceedings{McCloskey1989CatastrophicII,
  title={Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem},
  author={Michael McCloskey and Neal J. Cohen},
  year={1989},
  keywords={Classics},
  url={https://www.sciencedirect.com/science/article/pii/S0079742108605368}
}
@String(McCloskey1989CatastrophicII="Introduces CL and reveals the catastrophic forgetting problem")

@article{He2019TaskAC,
  title={Task Agnostic Continual Learning via Meta Learning},
  author={Xu He and Jakub Sygnowski and Alexandre Galashov and Andrei A. Rusu and Yee Whye Teh and Razvan Pascanu},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.05201},
    keywords={"Continual-Meta Learning"}
  url={https://arxiv.org/abs/1906.05201}
}
@String(He2019TaskAC="Introduces What & How framework; enables Task Agnostic CL with meta learned task inference")

@article{Harrison2019ContinuousMW,
  title={Continuous Meta-Learning without Tasks},
  author={James Harrison and Apoorva Sharma and Chelsea Finn and Marco Pavone},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.08866}
}

@article{van2019three,
  title={Three scenarios for continual learning},
  author={van de Ven, Gido M and Tolias, Andreas S},
  journal={arXiv preprint arXiv:1904.07734},
  year={2019},
  keywords={"Survey"},
  url={https://arxiv.org/abs/1904.07734},  
}
@String(van2019three="An extensive review of CL methods in three different scenarios (task-, domain-, and class-incremental learning)")

@inproceedings{lee2019overcoming,
  title={Overcoming Catastrophic Forgetting With Unlabeled Data in the Wild},
  author={Lee, Kibok and Lee, Kimin and Shin, Jinwoo and Lee, Honglak},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={312--321},
  year={2019},
    keywords={Distillation},
   url={https://arxiv.org/abs/1903.12648},
}
@String(lee2019overcoming="Introducing global distillation loss and balanced finetuning; leveraging unlabeled data in the open world setting (Single-head setting)")

@inproceedings{wu2019large,
  title={Large scale incremental learning},
  author={Wu, Yue and Chen, Yinpeng and Wang, Lijuan and Ye, Yuancheng and Liu, Zicheng and Guo, Yandong and Fu, Yun},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={374--382},
  year={2019},
    keywords={Distillation},
    url={https://arxiv.org/abs/1905.13260}
}
@String(wu2019large="Introducing bias parameters to the last fully connected layer to resolve the data imbalance issue (Single-head setting)")

@inproceedings{hou2018lifelong,
  title={Lifelong learning via progressive distillation and retrospection},
  author={Hou, Saihui and Pan, Xinyu and Change Loy, Chen and Wang, Zilei and Lin, Dahua},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={437--452},
  year={2018},
    keywords={Distillation},
    url={https://arxiv.org/abs/1905.13260}
}
@String(hou2018lifelong="Introducing an expert of the current task in the knowledge distillation method (Multi-head setting)")

@inproceedings{castro2018end,
  title={End-to-end incremental learning},
  author={Castro, Francisco M and Marin-Jimenez, Manuel J and Guil, Nicolas and Schmid, Cordelia and Alahari, Karteek},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={233--248},
  year={2018},
    keywords={Distillation},
    url={https://arxiv.org/abs/1807.09536}
}
@String(castro2018end="Finetuning the last fully connected layer with a balanced dataset to resolve the data imbalance issue (Single-head setting)")

@inproceedings{rebuffi2017icarl,
  title={icarl: Incremental classifier and representation learning},
  author={Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2001--2010},
  year={2017},
    keywords={Distillation, Rehearsal},
  url={https://arxiv.org/abs/1611.07725}
}
@String(rebuffi2017icarl="Binary cross-entropy loss for representation learning & exemplar memory (or coreset) for replay (Single-head setting)")


@InProceedings{Hou_2019_CVPR,
author={Hou, Saihui and Pan, Xinyu and Loy, Chen Change and Wang, Zilei and Lin, Dahua},
title={Learning a Unified Classifier Incrementally via Rebalancing},
booktitle={The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month={June},
year={2019},
    keywords={}
} 

@inproceedings{mallya2018packnet,
  title={Packnet: Adding multiple tasks to a single network by iterative pruning},
  author={Mallya, Arun and Lazebnik, Svetlana},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7765--7773},
  year={2018},
    keywords={}
}

@inproceedings{Mallya18Piggyback,
  title={Piggyback: Adapting a single network to multiple tasks by learning to mask weights},
  author={Mallya, Arun and Davis, Dillon and Lazebnik, Svetlana},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={67--82},
  year={2018},
    keywords={}
}

@inproceedings{wang17,
  title={Growing a brain: Fine-tuning by increasing model capacity},
  author={Wang, Yu-Xiong and Ramanan, Deva and Hebert, Martial},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2471--2480},
  year={2017},
    keywords={}
}



@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1126--1135},
  year={2017},
  organization={JMLR.org},
    keywords={}
}

@article{raghu2019rapid,
  title={Rapid learning or feature reuse? towards understanding the effectiveness of maml},
  author={Raghu, Aniruddh and Raghu, Maithra and Bengio, Samy and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1909.09157},
  year={2019},
    keywords={}
}
@inproceedings{kemker18fearnet,
title={FearNet: Brain-Inspired Model for Incremental Learning},
author={Ronald Kemker and Christopher Kanan},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=SJ1Xmf-Rb},
    keywords={}
}

@inproceedings{Gepperth16,
  TITLE={{Incremental learning algorithms and applications}},
  AUTHOR={Gepperth, Alexander and Hammer, Barbara},
  URL={https://hal.archives-ouvertes.fr/hal-01418129},
  BOOKTITLE={{European Symposium on Artificial Neural Networks (ESANN)}},
  ADDRESS={Bruges, Belgium},
  YEAR={2016},
  PDF={https://hal.archives-ouvertes.fr/hal-01418129/file/article.pdf},
  HAL_ID={hal-01418129},
  HAL_VERSION={v1},
    keywords={}
}

@article{Soltoggio2019Born,
title="Born to learn: The inspiration, progress, and future of evolved plastic artificial neural networks",
journal="Neural Networks",
volume="108",
pages="48 - 67",
year="2018",
issn="0893-6080",
doi="https://doi.org/10.1016/j.neunet.2018.07.013",
url="http://www.sciencedirect.com/science/article/pii/S0893608018302120",
author="Andrea Soltoggio and Kenneth O. Stanley and Sebastian Risi",
keywords={"Survey"},
}
@String(Soltoggio2019Born=" ")

@inproceedings{aljundi2017expertGate,
  title={Expert gate: Lifelong learning with a network of experts},
  author={Aljundi, Rahaf and Chakravarty, Punarjay and Tuytelaars, Tinne},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3366--3375},
  year={2017},
    keywords={}
}

@article{Silver13,
abstract={Lifelong Machine Learning Systems: Beyond Learning Algorithms},
author={Silver, Daniel L and Yang, Qiang and Li, Lianghao},
isbn={9781577356028},
journal={AAAI Spring Symposium Series},
keywords={AAAI Technical Report SS-13-05},
number={Solomonoff 1989},
pages={49--55},
title={{Lifelong Machine Learning Systems: Beyond Learning Algorithms}},
year={2013}
}

@article{Parisi18,
archivePrefix={arXiv},
arxivId={1805.10966},
author={Parisi, German I. and Jun, Tani and Weber, Cornelius and Wermter, Stefan},
eprint={1805.10966},
journal={arXiv preprint arXiv:1805.10966},
pages={1--20},
title={{Lifelong Learning of Spatiotemporal Representations with Dual-Memory Recurrent Self-Organization}},
url={http://arxiv.org/abs/1805.10966},
year={2018},
    keywords={}
}

@inproceedings{Lee16,
 author={Lee, Sang-Woo and Lee, Chung-Yeon and Kwak, Dong-Hyun and Kim, Jiwon and Kim, Jeonghee and Zhang, Byoung-Tak},
 title={Dual-memory Deep Learning Architectures for Lifelong Learning of Everyday Human Behaviors},
 booktitle={Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence},
 series={IJCAI'16},
 year={2016},
 isbn={978-1-57735-770-4},
 location={New York, New York, USA},
 pages={1669--1675},
 numpages={7},
 url={http://dl.acm.org/citation.cfm?id=3060832.3060854},
 acmid={3060854},
 publisher={AAAI Press},
    keywords={}
}

@article{Traore19DisCoRL,
  author   ={Ren{\'{e}} Traor{\'{e}} and
               Hugo Caselles{-}Dupr{\'{e}} and
               Timoth{\'{e}}e Lesort and
               Te Sun and
               Guanghang Cai and
               Natalia D{\'{\i}}az Rodr{\'{\i}}guez and
               David Filliat},
  title    ={DisCoRL: Continual Reinforcement Learning via Policy Distillation},
  journal  ={CoRR},
  volume   ={abs/1907.05855},
  year     ={2019},
  url      ={http://arxiv.org/abs/1907.05855},
  archivePrefix={arXiv},
  eprint   ={1907.05855},
  timestamp={Wed, 17 Jul 2019 10:27:36 +0200},
  biburl   ={https://dblp.org/rec/bib/journals/corr/abs-1907-05855},
  bibsource={dblp computer science bibliography, https://dblp.org},
    keywords={}
}

@inproceedings{Kalifou19,
  title={Continual Reinforcement Learning deployed in Real-life using PolicyDistillation and Sim2Real Transfer},
  author={Kalifou, René Traoré and Caselles-Dupré, Hugo and Lesort, Timothée and Sun, Te and Diaz-Rodriguez, Natalia and Filliat, David },
  booktitle={ICML Workshop on Multi-Task and Lifelong Learning},
  year={2019},
    keywords={}
}

@inproceedings{Rios19,
 author={Rios, Amanda and Itti, Laurent},
 title={Closed-loop Memory GAN for Continual Learning},
 booktitle={Proceedings of the 28th International Joint Conference on Artificial Intelligence},
 series={IJCAI'19},
 year={2019},
 isbn={978-0-9992411-4-1},
 location={Macao, China},
 pages={3332--3338},
 numpages={7},
 url={http://dl.acm.org/citation.cfm?id=3367471.3367504},
 acmid={3367504},
 publisher={AAAI Press},
    keywords={}
}

@INPROCEEDINGS{Hayes18NewMetrics,
author={T. L. Hayes and R. Kemker and N. D. Cahill and C. Kanan}, 
booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
title={New Metrics and Experimental Paradigms for Continual Learning}, 
year={2018}, 
volume={}, 
number={}, 
pages={2112-21123}, 
keywords={Robots;Measurement;Training;Task analysis;Computational modeling;Neural networks;Data models}, 
doi={10.1109/CVPRW.2018.00273}, 
ISSN={2160-7516}, 
month={June},}


@book{Chen2018Lifelong,
author={Chen, Zhiyuan and Liu, Bing and Brachman, Ronald and Stone, Peter and Rossi, Francesca},
title={Lifelong Machine Learning},
year={2018},
isbn={1681733021},
publisher={Morgan & Claypool Publishers},
edition={2nd},
keywords={"Book"}
}
@String(Chen2018Lifelong="Book on Continual Learning. Extensive review of older and newer algorithm; motivations and relation to other ML paradigms")


@article{Lesort19Continual,
title="Continual learning for robotics: Definition, framework, learning strategies, opportunities and challenges",
journal="Information Fusion",
volume="58",
pages="52 - 68",
year="2020",
issn="1566-2535",
doi="https://doi.org/10.1016/j.inffus.2019.12.004",
url="http://www.sciencedirect.com/science/article/pii/S1566253519307377",
author="Timothée Lesort and Vincenzo Lomonaco and Andrei Stoian and Davide Maltoni and David Filliat and Natalia Díaz-Rodríguez",
keywords="Robotics, Reinforcement Learning, Deep Learning, Lifelong Learning, Continual Learning, Catastrophic Forgetting, Survey",
}
@String(Lesort19Continual="Extensive review of CL methods and their applications in robotics and framework proposition for continual learning")

@article{French99,
author={French, Robert M.},
doi={10.1016/S1364-6613(99)01294-2},
isbn={13646613},
issn={13646613},
journal={Trends in Cognitive Sciences},
number={4},
pages={128--135},
pmid={10322466},
title={Catastrophic forgetting in connectionist networks},
volume={3},
year={1999},
    keywords={Classic},
    url={https://www.sciencedirect.com/science/article/abs/pii/S1364661399012942}
}

@inproceedings{titsias2019functional,
  title={Functional Regularisation for Continual Learning with Gaussian Processes},
  author={Titsias, Michalis K and Schwarz, Jonathan and Matthews, Alexander G de G and Pascanu, Razvan and Teh, Yee Whye},
  booktitle={International Conference on Learning Representations},
  year={2019},
    keywords={Regularization},
    url={https://arxiv.org/abs/1901.11356}
}
@String(titsias2019functional="functional regularisation for Continual Learning: avoids forgetting a previous task by constructing and memorising an approximate posterior belief over the underlying task-specific function")

@article{Maltoni18,
  title={Continuous Learning in Single-Incremental-Task Scenarios},
  author={Maltoni, Davide and Lomonaco, Vincenzo},
  journal={arXiv preprint arXiv:1806.08568},
  year={2018},
  keywords={"Empirical Study"}
}

@article{Kemker2017Measuring,
   author={{Kemker}, R. and {McClure}, M. and {Abitino}, A. and {Hayes}, T. and 
	{Kanan}, C.},
    title="{Measuring Catastrophic Forgetting in Neural Networks}",
  journal={ArXiv e-prints},
archivePrefix="arXiv",
   eprint={1708.02072},
 primaryClass="cs.AI",
 keywords={Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Empirical Study},
     year=2017,
    month={aug},
   adsurl={http://adsabs.harvard.edu/abs/2017arXiv170802072K},
  adsnote={Provided by the SAO/NASA Astrophysics Data System}
}

@InProceedings{Lomonaco17,
  title=	 {{CORe50: a New Dataset and Benchmark for Continuous Object Recognition}},
  author=	 {Vincenzo Lomonaco and Davide Maltoni},
  booktitle=	 {Proceedings of the 1st Annual Conference on Robot Learning},
  pages=	 {17--26},
  year=	 {2017},
  editor=	 {Sergey Levine and Vincent Vanhoucke and Ken Goldberg},
  volume=	 {78},
  series=	 {Proceedings of Machine Learning Research},
  address=	 {},
  month=	 {13--15 Nov},
 keywords={Empirical Study, Dataset},
  publisher=	 {PMLR},
  pdf=	 {http://proceedings.mlr.press/v78/lomonaco17a/lomonaco17a.pdf},
  url=	 {http://proceedings.mlr.press/v78/lomonaco17a.html}
}

@inproceedings{lesort2018marginal,
  title={Marginal replay vs conditional replay for continual learning},
  author={Lesort, Timoth{\'e}e and Gepperth, Alexander and Stoian, Andrei and Filliat, David},
  booktitle={International Conference on Artificial Neural Networks},
  pages={466--480},
  year={2019},
  organization={Springer},
    url={https://arxiv.org/abs/1810.12069},
    keywords={Generative Replay, }
}
@String(lesort2018marginal="Extensive evaluation of generative replay methods")

@article{Collet15,
  title={Herbdisc: Towards lifelong robotic object discovery},
  author={Collet, Alvaro and Xiong, Bo and Gurau, Corina and Hebert, Martial and Srinivasa, Siddhartha S},
  journal={The International Journal of Robotics Research},
  volume={34},
  number={1},
  pages={3--25},
  year={2015},
  publisher={SAGE Publications Sage UK: London, England},
    keywords={Robotics}
}


@article{beaulieu2020learning,
  title={Learning to Continually Learn},
  author={Beaulieu, Shawn and Frati, Lapo and Miconi, Thomas and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff and Cheney, Nick},
  journal={arXiv preprint arXiv:2002.09571},
  year={2020},
    keywords={Meta-Continual Learning},
    url={https://arxiv.org/abs/2002.09571}
}
@String(beaulieu2020learning="Follow-up of OML. Meta-learns an activation-gating function instead.")

@article{spigler2019meta,
  title={Meta-learnt priors slow down catastrophic forgetting in neural networks},
  author={Spigler, Giacomo},
  journal={arXiv preprint arXiv:1909.04170},
  year={2019},
    keywords={Meta-Continual Learning},
    url={https://arxiv.org/pdf/1909.04170.pdf}
}
@String(spigler2019meta="Learning MAML in a Meta continual learning way slows down forgetting")


@article{riemer2018learning,
  title={Learning to learn without forgetting by maximizing transfer and minimizing interference},
  author={Riemer, Matthew and Cases, Ignacio and Ajemian, Robert and Liu, Miao and Rish, Irina and Tu, Yuhai and Tesauro, Gerald},
  journal={arXiv preprint arXiv:1810.11910},
  year={2018},
    keywords={Meta-Continual Learning},
    url={https://arxiv.org/abs/1810.11910}
}

@inproceedings{rolnick2019experience,
  title={Experience replay for continual learning},
  author={Rolnick, David and Ahuja, Arun and Schwarz, Jonathan and Lillicrap, Timothy and Wayne, Gregory},
  booktitle={Advances in Neural Information Processing Systems},
  pages={348--358},
  year={2019},
    keywords={Reinforcement, Rehearsal},
  url={https://arxiv.org/abs/1811.11682}
}



@article{caccia2020online,
  title={Online Fast Adaptation and Knowledge Accumulation: a New Approach to Continual Learning},
  author={Caccia, Massimo and Rodriguez, Pau and Ostapenko, Oleksiy and Normandin, Fabrice and Lin, Min and Caccia, Lucas and Laradji, Issam and Rish, Irina and Lacoste, Alexandre and Vazquez, David and others},
  journal={CVPR2020 - Workshop on Continual Learning},
  year={2020},
  url={https://arxiv.org/abs/2003.05856},
  keywords={Continual-Meta Learning, Setting}
}
@String(caccia2020online="Proposes a new approach to CL evaluation more aligned with real-life applications, bringing CL closer to Online Learning and Open-World learning")


@inproceedings{
Yoon2020Scalable,
title={Scalable and Order-robust Continual Learning with Additive Parameter Decomposition},
author={Jaehong Yoon and Saehoon Kim and Eunho Yang and Sung Ju Hwang},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=r1gdj2EKPB}
}

@inproceedings{
Adel2020Continual,
title={Continual Learning with Adaptive Weights (CLAW)},
author={Tameem Adel and Han Zhao and Richard E. Turner},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Hklso24Kwr}
}


@inproceedings{
Lee2020A,
title={A Neural Dirichlet Process Mixture Model for Task-Free Continual Learning},
author={Soochan Lee and Junsoo Ha and Dongsu Zhang and Gunhee Kim},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SJxSOJStPr}
}


@inproceedings{
Li2020Compositional,
title={Compositional Language Continual Learning},
author={Yuanpeng Li and Liang Zhao and Kenneth Church and Mohamed Elhoseiny},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rklnDgHtDS}
}

@inproceedings{
Wen2020BatchEnsemble:,
title={BatchEnsemble: an Alternative Approach to Efficient Ensemble and Lifelong Learning},
author={Yeming Wen and Dustin Tran and Jimmy Ba},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Sklf1yrYDr}
}

@inproceedings{
Yoo2020SNOW:,
title={SNOW: Subscribing to Knowledge via Channel Pooling for Transfer & Lifelong Learning of Convolutional Neural Networks},
author={Chungkuk Yoo and Bumsoo Kang and Minsik Cho},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rJxtgJBKDr}
}

@inproceedings{
sun2020lamal,
title={LAMAL: LAnguage Modeling Is All You Need for Lifelong Language Learning},
author={Fan-Keng Sun and Cheng-Hao Ho and Hung-Yi Lee},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Skgxcn4YDS},
keywords={Applications}
}

@inproceedings{
Asghar2020Progressive,
title={Progressive Memory Banks for Incremental Domain Adaptation},
author={Nabiha Asghar and Lili Mou and Kira A. Selby and Kevin D. Pantasdo and Pascal Poupart and Xin Jiang},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=BkepbpNFwr}
}


@inproceedings{
Li2020Compositional,
title={Compositional Language Continual Learning},
author={Yuanpeng Li and Liang Zhao and Kenneth Church and Mohamed Elhoseiny},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rklnDgHtDS},
keywords={Applications, Setting}
}
@String(Li2020Compositional="method for compositional continual learning of sequence-to-sequence models")

