@incollection{Thrun95,
  title={Lifelong robot learning},
  author={Thrun, Sebastian and Mitchell, Tom M},
  booktitle={The biology and technology of intelligent autonomous agents},
  pages={165--196},
  year={1995},
  publisher={Springer},
  keywords={Classics}
}
@String(Thrun95="Argues knowledge transfer is essential if robots are to learn control with moderate learning times")

@article{Farquhar18,
  title={Towards Robust Evaluations of Continual Learning},
  author={Farquhar, Sebastian and Gal, Yarin},
  journal={arXiv preprint arXiv:1805.09733},
  year={2018},
    keywords = {Influentials, }
}
@String(Farquhar18="Proposes desideratas and reexamines the evaluation protocol")

@inproceedings{Chaudhry19,
  title={Efficient Lifelong Learning with {A-GEM}},
  author={Chaudhry, Arslan and Ranzato, Marc’Aurelio and Rohrbach, Marcus and Elhoseiny, Mohamed},
  booktitle={ICLR},
  year={2019},
  url = {https://arxiv.org/abs/1812.00420},
    keywords = {Rehearsal, Regularization, Influential}
}
@String(Chaudhry19="More efficient GEM; Introduces online continual learning")

@article{Kirkpatrick17,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proc. of the national academy of sciences},
  year={2017},
  publisher={National Acad Sciences},
    keywords = {Regularization, Influential}
}
@String(Kirkpatrick17="Introduces prior-focused methods")


@incollection{Lopez-Paz17,
title = {Gradient Episodic Memory for Continual Learning},
author = {Lopez-Paz, David and Ranzato, Marc-Aurelio},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {6467--6476},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7225-gradient-episodic-memory-for-continual-learning.pdf},
    keywords = {Rehearsal, Regularization, Influential}
}
@String(Lopez-Paz17="A model that alliviates CF via constrained optimization")


@inproceedings{Shin17,
  title={Continual learning with deep generative replay},
  author={Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2990--2999},
  year={2017},
    keywords = {Generative Replay, Influential}
}
@String(Shin17="Introduces generative replay")

@ARTICLE{Goodfellow13,
   author = {{Goodfellow}, I.~J. and {Mirza}, M. and {Xiao}, D. and {Courville}, A. and 
	{Bengio}, Y.},
    title = "{An Empirical Investigation of Catastrophic Forgetting in Gradient-Based Neural Networks}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1312.6211},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing, Empirical Study, Influential},
     year = {2013},
    month = {dec},
   adsurl = {http://adsabs.harvard.edu/abs/2013arXiv1312.6211G},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@String(Goodfellow13="Investigates CF in neural networks")

@misc{lange2019continual,
    title={Continual learning: A comparative study on how to defy forgetting in classification tasks},
    author={Matthias De Lange and Rahaf Aljundi and Marc Masana and Sarah Parisot and Xu Jia and Ales Leonardis and Gregory Slabaugh and Tinne Tuytelaars},
    year={2019},
    eprint={1909.08383},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    keywords = "Survey"
}
@String(lange2019continual = "Extensive empirical study of CL methods (in the multi-head setting)")

@article{Parisi18review,
title = "Continual lifelong learning with neural networks: A review",
journal = "Neural Networks",
volume = "113",
pages = "54 - 71",
year = "2019",
issn = "0893-6080",
doi = "https://doi.org/10.1016/j.neunet.2019.01.012",
url = "http://www.sciencedirect.com/science/article/pii/S0893608019300231",
author = "German I. Parisi and Ronald Kemker and Jose L. Part and Christopher Kanan and Stefan Wermter",
keywords = "Continual learning, Lifelong learning, Catastrophic forgetting, Developmental systems, Memory consolidation, Survey"
}
@String(Parisi18review="An extensive review of CL")

@inproceedings{hung2019compacting,
  title={Compacting, Picking and Growing for Unforgetting Continual Learning},
  author={Hung, Ching-Yi and Tu, Cheng-Hao and Wu, Cheng-En and Chen, Chien-Hung and Chan, Yi-Ming and Chen, Chu-Song},
  booktitle={Advances in Neural Information Processing Systems},
  pages={13647--13657},
  year={2019},
    keywords = {Hybrid}
}


@article{Swaroop2019ImprovingAU,
  title={Improving and Understanding Variational Continual Learning},
  author={Siddharth Swaroop and Cuong V. Nguyen and Thang D. Bui and Richard E. Turner},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.02099},
    keywords = {Regularization}
}

@article{lee2020neural,
  title={A Neural Dirichlet Process Mixture Model for Task-Free Continual Learning},
  author={Lee, Soochan and Ha, Junsoo and Zhang, Dongsu and Kim, Gunhee},
  journal={arXiv preprint arXiv:2001.00689},
  year={2020},
    keywords = {Dynamic Architecture}
}


@article{Ebrahimi2019UncertaintyguidedCL,
  title={Uncertainty-guided Continual Learning with Bayesian Neural Networks},
  author={Sayna Ebrahimi and Mohamed Elhoseiny and Trevor Darrell and Marcus Rohrbach},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.02425},
    keywords = {Regularization}
}

@incollection{NIPS2019_8690,
title = {Uncertainty-based Continual Learning with Adaptive Regularization},
author = {Ahn, Hongjoon and Cha, Sungmin and Lee, Donggyu and Moon, Taesup},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {4394--4404},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8690-uncertainty-based-continual-learning-with-adaptive-regularization.pdf},
    keywords = {Regularization}
}

@misc{zeno2018task,
    title={Task Agnostic Continual Learning Using Online Variational Bayes},
    author={Chen Zeno and Itay Golan and Elad Hoffer and Daniel Soudry},
    year={2018},
    eprint={1803.10123},
    archivePrefix={arXiv},
    primaryClass={stat.ML},
    keywords = {Regularization}
}

@article{adel2019continual,
  title={Continual Learning with Adaptive Weights (CLAW)},
  author={Adel, Tameem and Zhao, Han and Turner, Richard E},
  journal={arXiv preprint arXiv:1911.09514},
  year={2019},
    keywords = {Dynamic Architecture}
}

@article{DBLP:journals/corr/abs-1902-09432,
  author    = {Jaehong Yoon and
               Saehoon Kim and
               Eunho Yang and
               Sung Ju Hwang},
  title     = {{ORACLE:} Order Robust Adaptive Continual LEarning},
  journal   = {CoRR},
  volume    = {abs/1902.09432},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.09432},
  archivePrefix = {arXiv},
  eprint    = {1902.09432},
  timestamp = {Tue, 21 May 2019 18:03:36 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-09432.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
    keywords = {Dynamic Architecture}
}

@article{Rajasegaran2019Random,
  author    = {Jathushan Rajasegaran and
               Munawar Hayat and
               Salman H. Khan and
               Fahad Shahbaz Khan and
               Ling Shao},
  title     = {Random Path Selection for Incremental Learning},
  journal   = {CoRR},
  volume    = {abs/1906.01120},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.01120},
  archivePrefix = {arXiv},
  eprint    = {1906.01120},
  timestamp = {Fri, 06 Dec 2019 16:34:40 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-01120.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
    keywords = {Dynamic Architecture}
}



@inproceedings{He18,
title={Overcoming Catastrophic Interference using Conceptor-Aided Backpropagation},
author={Xu He and Herbert Jaeger},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=B1al7jg0b},
    keywords = {Regularization}
}
@inproceedings{Pentina15,
  title={Lifelong learning with non-iid tasks},
  author={Pentina, Anastasia and Lampert, Christoph H},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1540--1548},
  year={2015},
    keywords = {}
}

@article{Serra18,
  title = 	 {Overcoming Catastrophic Forgetting with Hard Attention to the Task},
  author = 	 {Serra, Joan and Suris, Didac and Miron, Marius and Karatzoglou, Alexandros},
  journal   = {ICML},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {4548--4557},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/serra18a/serra18a.pdf},
  url = 	 {http://proceedings.mlr.press/v80/serra18a.html},
    keywords = {Regularization}
}

@inproceedings{chaudhry2018riemannian,
  title={Riemannian Walk for Incremental Learning: Understanding Forgetting and Intransigence},
  author={Chaudhry, Arslan and Dokania, Puneet K and Ajanthan, Thalaiyasingam and Torr, Philip HS},
  booktitle={ECCV},
  year={2018},
    keywords = {Regularization}
}

@article{Aljundi17,
  author    = {Rahaf Aljundi and Francesca Babiloni and Mohamed Elhoseiny and Marcus Rohrbach and Tinne Tuytelaars},
  title     = {Memory Aware Synapses: Learning what (not) to forget},
  journal   = {CoRR},
  volume    = {abs/1711.09601},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.09601},
  archivePrefix = {arXiv},
  eprint    = {1711.09601},
  timestamp = {Mon, 13 Aug 2018 16:47:14 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1711-09601},
  bibsource = {dblp computer science bibliography, https://dblp.org},
    keywords = {Regularization}
}

@inproceedings{Nguyen17,
title={Variational Continual Learning},
author={Cuong V. Nguyen and Yingzhen Li and Thang D. Bui and Richard E. Turner},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=BkQqq0gRb},
    keywords = {Regularization}
}

@InProceedings{Zenke17,
  title = 	 {Continual Learning Through Synaptic Intelligence},
  author = 	 {{Zenke}, Friedeman and {Poole}, Ben and {Ganguli}, Surya },
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {3987--3995},
  year = 	 {2017},
  editor = 	 {Doina Precup and Yee Whye Teh},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {International Convention Centre, Sydney, Australia},
  month = 	 {06--11 Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/zenke17a/zenke17a.pdf},
  url = 	 {http://proceedings.mlr.press/v70/zenke17a.html},
    keywords = {Regularization}
}
@String{Zenke17="Synaptic Intelligence (SI). Importance of parameter measured based on their contribution to change in the loss. "}

@article{Li17,
  title={Learning without forgetting},
  author={Li, Zhizhong and Hoiem, Derek},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2017},
  publisher={IEEE},
    keywords = {Distillation}
}

@misc{li2019continual,
    title={Continual Learning Using Bayesian Neural Networks},
    author={HongLin Li and Payam Barnaghi and Shirin Enshaeifar and Frieder Ganz},
    year={2019},
    eprint={1910.04112},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    keywords = {}
}

@misc{
rosenfeld2018incremental,
title={Incremental Learning through Deep Adaptation},
author={Amir Rosenfeld and John K. Tsotsos},
year={2018},
url={https://openreview.net/forum?id=ryj0790hb},
    keywords = {Dynamic Architecture}
}

@ARTICLE{Rusu16progressive,
   author = {{Rusu}, A.~A. and {Rabinowitz}, N.~C. and {Desjardins}, G. and 
	{Soyer}, H. and {Kirkpatrick}, J. and {Kavukcuoglu}, K. and 
	{Pascanu}, R. and {Hadsell}, R.},
    title = "{Progressive Neural Networks}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1606.04671},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning, Dynamic Architecture},
     year = 2016,
    month = {jun},
   adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160604671R},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@misc{farajtabar2019orthogonal,
    title={Orthogonal Gradient Descent for Continual Learning},
    author={Mehrdad Farajtabar and Navid Azizan and Alex Mott and Ang Li},
    year={2019},
    eprint={1910.07104},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    keywords = {Rehearsal}
}

@incollection{Aljundi2019Gradient,
title = {Gradient based sample selection for online continual learning},
author = {Aljundi, Rahaf and Lin, Min and Goujaud, Baptiste and Bengio, Yoshua},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {11816--11825},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9354-gradient-based-sample-selection-for-online-continual-learning.pdf},
    keywords = {Rehearsal}
}

@incollection{Aljundi2019Online,
title = {Online Continual Learning with Maximal Interfered Retrieval},
author = {Aljundi, Rahaf and Belilovsky, Eugene and Tuytelaars, Tinne and Charlin, Laurent and Caccia, Massimo and Lin, Min and Page-Caccia, Lucas},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {11849--11860},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9357-online-continual-learning-with-maximal-interfered-retrieval.pdf},
    keywords = {}
}

@article{caccia2019online,
  title={Online Learned Continual Compression with Stacked Quantization Module},
  author={Caccia, Lucas and Belilovsky, Eugene and Caccia, Massimo and Pineau, Joelle},
  journal={arXiv preprint arXiv:1911.08019},
  year={2019},
    keywords = {Rehearsal}
}


@article{Ven2018GenerativeRW,
  title={Generative replay with feedback connections as a general strategy for continual learning},
  author={Michiel van der Ven and Andreas S. Tolias},
  journal={ArXiv},
  year={2018},
  volume={abs/1809.10635},
    keywords = {}
}

@incollection{Javed2019Meta,
title = {Meta-Learning Representations for Continual Learning},
author = {Javed, Khurram and White, Martha},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {1818--1828},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8458-meta-learning-representations-for-continual-learning.pdf},
    keywords = {Meta Continual Learning}
}

@misc{luo2019learning,
    title={Learning from the Past: Continual Meta-Learning via Bayesian Graph Modeling},
    author={Yadan Luo and Zi Huang and Zheng Zhang and Ziwei Wang and Mahsa Baktashmotlagh and Yang Yang},
    year={2019},
    eprint={1911.04695},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    keywords = {Continual Meta Learning}
}

@inproceedings{
Kurle2020Continual,
title={Continual Learning with Bayesian Neural Networks for Non-Stationary Data},
author={Richard Kurle and Botond Cseke and Alexej Klushyn and Patrick van der Smagt and Stephan Günnemann},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SJlsFpVtDB},
    keywords = {Regularization}
}

@InProceedings{pmlr-v97-finn19a,
  title = 	 {Online Meta-Learning},
  author = 	 {Finn, Chelsea and Rajeswaran, Aravind and Kakade, Sham and Levine, Sergey},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {1920--1930},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Long Beach, California, USA},
  month = 	 {09--15 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/finn19a/finn19a.pdf},
  url = 	 {http://proceedings.mlr.press/v97/finn19a.html},
    keywords = {Continual Meta Learning}
}

@incollection{NIPS2019_9112,
title = {Reconciling meta-learning and continual learning with online mixtures of tasks},
author = {Jerfel, Ghassen and Grant, Erin and Griffiths, Tom and Heller, Katherine A},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {9119--9130},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9112-reconciling-meta-learning-and-continual-learning-with-online-mixtures-of-tasks.pdf},
    keywords = {Continual Meta Learning}
}

@inproceedings{
nagabandi2018deep,
title={Deep Online Learning Via Meta-Learning: Continual Adaptation for Model-Based {RL}},
author={Anusha Nagabandi and Chelsea Finn and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HyxAfnA5tm},
    keywords = {Continual Meta Learning}
}

@misc{rao2019continual,
    title={Continual Unsupervised Representation Learning},
    author={Dushyant Rao and Francesco Visin and Andrei A. Rusu and Yee Whye Teh and Razvan Pascanu and Raia Hadsell},
    year={2019},
    eprint={1910.14481},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    keywords = {Generative Modeling}
}

@inproceedings{lesort2018generative,
  TITLE = {{Generative Models from the perspective of Continual Learning}},
  AUTHOR = {Lesort, Timoth{\'e}e and Caselles-Dupr{\'e}, Hugo and Garcia-Ortiz, Michael and Goudou, Jean-Fran{\c c}ois and Filliat, David},
  URL = {https://hal.archives-ouvertes.fr/hal-01951954},
  BOOKTITLE = {{IJCNN - International Joint Conference on Neural Networks}},
  ADDRESS = {Budapest, Hungary},
  YEAR = {2019},
  MONTH = {Jul},
  PDF = {https://hal.archives-ouvertes.fr/hal-01951954/file/_NIPS_CL_Workshop__Continual_learning_for_generative_models.pdf},
  HAL_ID = {hal-01951954},
  keywords = {"Empirical Study", "Generative Modeling", "Generative Replay"},
  HAL_VERSION = {v1},
}

@article{Ramapuram17,
  title={Lifelong Generative Modeling},
  author={Ramapuram, Jason and Gregorova, Magda and Kalousis, Alexandros},
  journal={arXiv preprint arXiv:1705.09847},
  year={2017},
    keywords = {Generative Modeling}
}

@inproceedings{Alet2018ModularM,
  title={Modular meta-learning},
  author={Ferran Alet and Tom{\'a}s Lozano-P{\'e}rez and Leslie Pack Kaelbling},
  booktitle={CoRL},
  year={2018},
    keywords = {}
}

@inproceedings{
toneva2018an,
title={An Empirical Study of Example Forgetting during Deep Neural Network Learning},
author={Mariya Toneva and Alessandro Sordoni and Remi Tachet des Combes and Adam Trischler and Yoshua Bengio and Geoffrey J. Gordon},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=BJlxm30cKm},
    keywords = {}
}

@inproceedings{
anonymous2020continual,
title={Continual learning with hypernetworks},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SJgwNerKvB},
note={under review},
    keywords = {Hybrid}
}

@inproceedings{McCloskey1989CatastrophicII,
  title={Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem},
  author={Michael McCloskey and Neal J. Cohen},
  year={1989},
  keywords={Classics}
}
@String(McCloskey1989CatastrophicII="Introduces CL and reveals the catastrophic forgetting problem")

@article{He2019TaskAC,
  title={Task Agnostic Continual Learning via Meta Learning},
  author={Xu He and Jakub Sygnowski and Alexandre Galashov and Andrei A. Rusu and Yee Whye Teh and Razvan Pascanu},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.05201},
    keywords = {"Continual Meta Learning"}
}

@article{Harrison2019ContinuousMW,
  title={Continuous Meta-Learning without Tasks},
  author={James Harrison and Apoorva Sharma and Chelsea Finn and Marco Pavone},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.08866}
}

@article{van2019three,
  title={Three scenarios for continual learning},
  author={van de Ven, Gido M and Tolias, Andreas S},
  journal={arXiv preprint arXiv:1904.07734},
  year={2019},
  keywords = {"Survey"}
}
@String(van2019three="An extensive review of CL methods in three different scenarios (task-, domain-, and class-incremental learning)")

@inproceedings{lee2019overcoming,
  title={Overcoming Catastrophic Forgetting With Unlabeled Data in the Wild},
  author={Lee, Kibok and Lee, Kimin and Shin, Jinwoo and Lee, Honglak},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={312--321},
  year={2019},
    keywords = {Distillation}
}

@inproceedings{wu2019large,
  title={Large scale incremental learning},
  author={Wu, Yue and Chen, Yinpeng and Wang, Lijuan and Ye, Yuancheng and Liu, Zicheng and Guo, Yandong and Fu, Yun},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={374--382},
  year={2019},
    keywords = {Distillation}
}

@inproceedings{hou2018lifelong,
  title={Lifelong learning via progressive distillation and retrospection},
  author={Hou, Saihui and Pan, Xinyu and Change Loy, Chen and Wang, Zilei and Lin, Dahua},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={437--452},
  year={2018},
    keywords = {Distillation}
}

@inproceedings{castro2018end,
  title={End-to-end incremental learning},
  author={Castro, Francisco M and Mar{\'\i}n-Jim{\'e}nez, Manuel J and Guil, Nicol{\'a}s and Schmid, Cordelia and Alahari, Karteek},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={233--248},
  year={2018},
    keywords = {Distillation}
}

@inproceedings{rebuffi2017icarl,
  title={icarl: Incremental classifier and representation learning},
  author={Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2001--2010},
  year={2017},
    keywords = {Distillation, Rehearsal}
}

@InProceedings{Hou_2019_CVPR,
author = {Hou, Saihui and Pan, Xinyu and Loy, Chen Change and Wang, Zilei and Lin, Dahua},
title = {Learning a Unified Classifier Incrementally via Rebalancing},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019},
    keywords = {}
} 

@inproceedings{mallya2018packnet,
  title={Packnet: Adding multiple tasks to a single network by iterative pruning},
  author={Mallya, Arun and Lazebnik, Svetlana},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7765--7773},
  year={2018},
    keywords = {}
}

@inproceedings{Mallya18Piggyback,
  title={Piggyback: Adapting a single network to multiple tasks by learning to mask weights},
  author={Mallya, Arun and Davis, Dillon and Lazebnik, Svetlana},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={67--82},
  year={2018},
    keywords = {}
}

@inproceedings{wang17,
  title={Growing a brain: Fine-tuning by increasing model capacity},
  author={Wang, Yu-Xiong and Ramanan, Deva and Hebert, Martial},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2471--2480},
  year={2017},
    keywords = {}
}

@inproceedings{schwarz2018progress,
  title={Progress \& compress: A scalable framework for continual learning},
  author={Schwarz, Jonathan and Luketina, Jelena and Czarnecki, Wojciech M and Grabska-Barwinska, Agnieszka and Teh, Yee Whye and Pascanu, Razvan and Hadsell, Raia},
  booktitle={ICML},
  year={2018},
    keywords = {Regularization}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1126--1135},
  year={2017},
  organization={JMLR.org},
    keywords = {}
}

@article{raghu2019rapid,
  title={Rapid learning or feature reuse? towards understanding the effectiveness of maml},
  author={Raghu, Aniruddh and Raghu, Maithra and Bengio, Samy and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1909.09157},
  year={2019},
    keywords = {}
}
@inproceedings{kemker18fearnet,
title={FearNet: Brain-Inspired Model for Incremental Learning},
author={Ronald Kemker and Christopher Kanan},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=SJ1Xmf-Rb},
    keywords = {}
}

@inproceedings{Gepperth16,
  TITLE = {{Incremental learning algorithms and applications}},
  AUTHOR = {Gepperth, Alexander and Hammer, Barbara},
  URL = {https://hal.archives-ouvertes.fr/hal-01418129},
  BOOKTITLE = {{European Symposium on Artificial Neural Networks (ESANN)}},
  ADDRESS = {Bruges, Belgium},
  YEAR = {2016},
  PDF = {https://hal.archives-ouvertes.fr/hal-01418129/file/article.pdf},
  HAL_ID = {hal-01418129},
  HAL_VERSION = {v1},
    keywords = {}
}

@article{Soltoggio2019Born,
title = "Born to learn: The inspiration, progress, and future of evolved plastic artificial neural networks",
journal = "Neural Networks",
volume = "108",
pages = "48 - 67",
year = "2018",
issn = "0893-6080",
doi = "https://doi.org/10.1016/j.neunet.2018.07.013",
url = "http://www.sciencedirect.com/science/article/pii/S0893608018302120",
author = "Andrea Soltoggio and Kenneth O. Stanley and Sebastian Risi",
keywords = "Artificial neural networks, Lifelong learning, Plasticity, Evolutionary computation, Survey",
abstract = "Biological neural networks are systems of extraordinary computational capabilities shaped by evolution, development, and lifelong learning. The interplay of these elements leads to the emergence of biological intelligence. Inspired by such intricate natural phenomena, Evolved Plastic Artificial Neural Networks (EPANNs) employ simulated evolution in-silico to breed plastic neural networks with the aim to autonomously design and create learning systems. EPANN experiments evolve networks that include both innate properties and the ability to change and learn in response to experiences in different environments and problem domains. EPANNs’ aims include autonomously creating learning systems, bootstrapping learning from scratch, recovering performance in unseen conditions, testing the computational advantages of particular neural components, and deriving hypotheses on the emergence of biological learning. Thus, EPANNs may include a large variety of different neuron types and dynamics, network architectures, plasticity rules, and other factors. While EPANNs have seen considerable progress over the last two decades, current scientific and technological advances in artificial neural networks are setting the conditions for radically new approaches and results. Exploiting the increased availability of computational resources and of simulation environments, the often challenging task of hand-designing learning neural networks could be replaced by more autonomous and creative processes. This paper brings together a variety of inspiring ideas that define the field of EPANNs. The main methods and results are reviewed. Finally, new opportunities and possible developments are presented."
}

@inproceedings{aljundi2017expertGate,
  title={Expert gate: Lifelong learning with a network of experts},
  author={Aljundi, Rahaf and Chakravarty, Punarjay and Tuytelaars, Tinne},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3366--3375},
  year={2017},
    keywords = {}
}

@article{Silver13,
abstract = {Lifelong Machine Learning Systems: Beyond Learning Algorithms},
author = {Silver, Daniel L and Yang, Qiang and Li, Lianghao},
isbn = {9781577356028},
journal = {AAAI Spring Symposium Series},
keywords = {AAAI Technical Report SS-13-05},
number = {Solomonoff 1989},
pages = {49--55},
title = {{Lifelong Machine Learning Systems: Beyond Learning Algorithms}},
year = {2013}
}

@article{Parisi18,
archivePrefix = {arXiv},
arxivId = {1805.10966},
author = {Parisi, German I. and Jun, Tani and Weber, Cornelius and Wermter, Stefan},
eprint = {1805.10966},
journal = {arXiv preprint arXiv:1805.10966},
pages = {1--20},
title = {{Lifelong Learning of Spatiotemporal Representations with Dual-Memory Recurrent Self-Organization}},
url = {http://arxiv.org/abs/1805.10966},
year = {2018},
    keywords = {}
}

@inproceedings{Lee16,
 author = {Lee, Sang-Woo and Lee, Chung-Yeon and Kwak, Dong-Hyun and Kim, Jiwon and Kim, Jeonghee and Zhang, Byoung-Tak},
 title = {Dual-memory Deep Learning Architectures for Lifelong Learning of Everyday Human Behaviors},
 booktitle = {Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence},
 series = {IJCAI'16},
 year = {2016},
 isbn = {978-1-57735-770-4},
 location = {New York, New York, USA},
 pages = {1669--1675},
 numpages = {7},
 url = {http://dl.acm.org/citation.cfm?id=3060832.3060854},
 acmid = {3060854},
 publisher = {AAAI Press},
    keywords = {}
}

@article{Traore19DisCoRL,
  author    = {Ren{\'{e}} Traor{\'{e}} and
               Hugo Caselles{-}Dupr{\'{e}} and
               Timoth{\'{e}}e Lesort and
               Te Sun and
               Guanghang Cai and
               Natalia D{\'{\i}}az Rodr{\'{\i}}guez and
               David Filliat},
  title     = {DisCoRL: Continual Reinforcement Learning via Policy Distillation},
  journal   = {CoRR},
  volume    = {abs/1907.05855},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.05855},
  archivePrefix = {arXiv},
  eprint    = {1907.05855},
  timestamp = {Wed, 17 Jul 2019 10:27:36 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1907-05855},
  bibsource = {dblp computer science bibliography, https://dblp.org},
    keywords = {}
}

@inproceedings{Kalifou19,
  title={Continual Reinforcement Learning deployed in Real-life using PolicyDistillation and Sim2Real Transfer},
  author={Kalifou, René Traoré and Caselles-Dupré, Hugo and Lesort, Timothée and Sun, Te and Diaz-Rodriguez, Natalia and Filliat, David },
  booktitle={ICML Workshop on Multi-Task and Lifelong Learning},
  year={2019},
    keywords = {}
}

@inproceedings{Rios19,
 author = {Rios, Amanda and Itti, Laurent},
 title = {Closed-loop Memory GAN for Continual Learning},
 booktitle = {Proceedings of the 28th International Joint Conference on Artificial Intelligence},
 series = {IJCAI'19},
 year = {2019},
 isbn = {978-0-9992411-4-1},
 location = {Macao, China},
 pages = {3332--3338},
 numpages = {7},
 url = {http://dl.acm.org/citation.cfm?id=3367471.3367504},
 acmid = {3367504},
 publisher = {AAAI Press},
    keywords = {}
}

@INPROCEEDINGS{Hayes18NewMetrics,
author={T. L. Hayes and R. Kemker and N. D. Cahill and C. Kanan}, 
booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
title={New Metrics and Experimental Paradigms for Continual Learning}, 
year={2018}, 
volume={}, 
number={}, 
pages={2112-21123}, 
keywords={Robots;Measurement;Training;Task analysis;Computational modeling;Neural networks;Data models}, 
doi={10.1109/CVPRW.2018.00273}, 
ISSN={2160-7516}, 
month={June},}


@book{Chen2018Lifelong,
author = {Chen, Zhiyuan and Liu, Bing and Brachman, Ronald and Stone, Peter and Rossi, Francesca},
title = {Lifelong Machine Learning},
year = {2018},
isbn = {1681733021},
publisher = {Morgan & Claypool Publishers},
edition = {2nd},
keywords = {"Book"}
}
@String(Chen2018Lifelong="Book on Continual Learning. Extensive review of older and newer algorithm; motivations and relation to other ML paradigms")


@article{Lesort19Continual,
title = "Continual learning for robotics: Definition, framework, learning strategies, opportunities and challenges",
journal = "Information Fusion",
volume = "58",
pages = "52 - 68",
year = "2020",
issn = "1566-2535",
doi = "https://doi.org/10.1016/j.inffus.2019.12.004",
url = "http://www.sciencedirect.com/science/article/pii/S1566253519307377",
author = "Timothée Lesort and Vincenzo Lomonaco and Andrei Stoian and Davide Maltoni and David Filliat and Natalia Díaz-Rodríguez",
keywords = "Robotics, Reinforcement Learning, Deep Learning, Lifelong Learning, Continual Learning, Catastrophic Forgetting, Survey",
abstract = "Continual learning (CL) is a particular machine learning paradigm where the data distribution and learning objective change through time, or where all the training data and objective criteria are never available at once. The evolution of the learning process is modeled by a sequence of learning experiences where the goal is to be able to learn new skills all along the sequence without forgetting what has been previously learned. CL can be seen as an online learning where knowledge fusion needs to take place in order to learn from streams of data presented sequentially in time. Continual learning also aims at the same time at optimizing the memory, the computation power and the speed during the learning process. An important challenge for machine learning is not necessarily finding solutions that work in the real world but rather finding stable algorithms that can learn in real world. Hence, the ideal approach would be tackling the real world in a embodied platform: an autonomous agent. Continual learning would then be effective in an autonomous agent or robot, which would learn autonomously through time about the external world, and incrementally develop a set of complex skills and knowledge.Robotic agents have to learn to adapt and interact with their environment using a continuous stream of observations. Some recent approaches aim at tackling continual learning for robotics, but most recent papers on continual learning only experiment approaches in simulation or with static datasets. Unfortunately, the evaluation of those algorithms does not provide insights on whether their solutions may help continual learning in the context of robotics. This paper aims at reviewing the existing state of the art of continual learning, summarizing existing benchmarks and metrics, and proposing a framework for presenting and evaluating both robotics and non robotics approaches in a way that makes transfer between both fields easier. We put light on continual learning in the context of robotics to create connections between fields and normalize approaches."
}
@String(Lesort19Continual="Extensive review of CL methods and their applications in robotics and framework proposition for continual learning")

@article{French99,
abstract = {All natural cognitive systems, and, in particular, our own, gradually forget previously learned information. Plausible models of human cognition should therefore exhibit similar patterns of gradual forgetting of old information as new information is acquired. Only rarely does new learning in natural cognitive systems completely disrupt or erase previously learned information; that is, natural cognitive systems do not, in general, forget 'catastrophically'. Unfortunately, though, catastrophic forgetting does occur under certain circumstances in distributed connectionist networks. The very features that give these networks their remarkable abilities to generalize, to function in presence of degraded input, and so on, are found to be the root cause of catastrophic forgetting. The challenge in this field is to discover how to keep the advantages of distributed connectionist networks while avoiding the problem of catastrophic forgetting. In this article the causes, consequences and numerous solutions to the problem of catastrophic forgetting in neural networks are examined. The review will consider how the brain might have overcome this problem and will also explore the consequences of this solution for distributed connectionist networks.},
author = {French, Robert M.},
doi = {10.1016/S1364-6613(99)01294-2},
isbn = {13646613},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {4},
pages = {128--135},
pmid = {10322466},
title = {{Catastrophic forgetting in connectionist networks}},
volume = {3},
year = {1999},
    keywords = {}
}
@inproceedings{titsias2019functional,
  title={Functional Regularisation for Continual Learning with Gaussian Processes},
  author={Titsias, Michalis K and Schwarz, Jonathan and Matthews, Alexander G de G and Pascanu, Razvan and Teh, Yee Whye},
  booktitle={International Conference on Learning Representations},
  year={2019},
    keywords = {Regularization}
}


@article{Maltoni18,
  title={Continuous Learning in Single-Incremental-Task Scenarios},
  author={Maltoni, Davide and Lomonaco, Vincenzo},
  journal={arXiv preprint arXiv:1806.08568},
  year={2018}
  keywords = {"Empirical Study"}
}

@article{Kemker2017Measuring,
   author = {{Kemker}, R. and {McClure}, M. and {Abitino}, A. and {Hayes}, T. and 
	{Kanan}, C.},
    title = "{Measuring Catastrophic Forgetting in Neural Networks}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1708.02072},
 primaryClass = "cs.AI",
 keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Empirical Study},
     year = 2017,
    month = {aug},
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170802072K},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@InProceedings{Lomonaco17,
  title = 	 {{CORe50: a New Dataset and Benchmark for Continuous Object Recognition}},
  author = 	 {Vincenzo Lomonaco and Davide Maltoni},
  booktitle = 	 {Proceedings of the 1st Annual Conference on Robot Learning},
  pages = 	 {17--26},
  year = 	 {2017},
  editor = 	 {Sergey Levine and Vincent Vanhoucke and Ken Goldberg},
  volume = 	 {78},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {13--15 Nov},
 keywords = {Empirical Study, Dataset},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v78/lomonaco17a/lomonaco17a.pdf},
  url = 	 {http://proceedings.mlr.press/v78/lomonaco17a.html}
}

@inproceedings{lesort2018marginal,
  title={Marginal replay vs conditional replay for continual learning},
  author={Lesort, Timoth{\'e}e and Gepperth, Alexander and Stoian, Andrei and Filliat, David},
  booktitle={International Conference on Artificial Neural Networks},
  pages={466--480},
  year={2019},
  organization={Springer},
    keywords = {Generative Replay", Classification}
}

@article{Collet15,
  title={Herbdisc: Towards lifelong robotic object discovery},
  author={Collet, Alvaro and Xiong, Bo and Gurau, Corina and Hebert, Martial and Srinivasa, Siddhartha S},
  journal={The International Journal of Robotics Research},
  volume={34},
  number={1},
  pages={3--25},
  year={2015},
  publisher={SAGE Publications Sage UK: London, England},
    keywords = {Robotics}
}


@article{beaulieu2020learning,
  title={Learning to Continually Learn},
  author={Beaulieu, Shawn and Frati, Lapo and Miconi, Thomas and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff and Cheney, Nick},
  journal={arXiv preprint arXiv:2002.09571},
  year={2020},
    keywords = {Meta Continual Learning}
}

@article{spigler2019meta,
  title={Meta-learnt priors slow down catastrophic forgetting in neural networks},
  author={Spigler, Giacomo},
  journal={arXiv preprint arXiv:1909.04170},
  year={2019},
    keywords = {Meta Continual Learning}
}


@article{riemer2018learning,
  title={Learning to learn without forgetting by maximizing transfer and minimizing interference},
  author={Riemer, Matthew and Cases, Ignacio and Ajemian, Robert and Liu, Miao and Rish, Irina and Tu, Yuhai and Tesauro, Gerald},
  journal={arXiv preprint arXiv:1810.11910},
  year={2018},
    keywords = {Meta Continual Learning}
}

@inproceedings{rolnick2019experience,
  title={Experience replay for continual learning},
  author={Rolnick, David and Ahuja, Arun and Schwarz, Jonathan and Lillicrap, Timothy and Wayne, Gregory},
  booktitle={Advances in Neural Information Processing Systems},
  pages={348--358},
  year={2019},
    keywords = {Reinforcement, Rehearsal}
}



